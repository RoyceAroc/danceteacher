<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Pose Detection Demo</title>
    <style>
        canvas {
    border: 1px solid black;
    width: 100vw;
    height: auto; 
    max-width: 100%; 
}
    </style>
</head>
<body>
    <video style="display: none;" id="video" muted playsinline>
        <source src="11.mp4" type="video/mp4">
    </video>
    <canvas id="canvas"></canvas>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@3.13.0/dist/tf.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/pose-detection@0.0.3/dist/pose-detection.min.js"></script>
    <script>
        function dist(a, b) {
            return Math.sqrt((a[0] - b[0]) ** 2 + (a[1] - b[1]) ** 2)
        }

        // Get the video and canvas elements
        const video = document.getElementById('video');
        const canvas = document.getElementById('canvas');
        const ctx = canvas.getContext('2d');
        let detectorMain;
        let intervalId;
        let videoWidth;
        let videoHeight;
        let threshold = 0.45;
        let previousMidpoint = [];
        let previousMovementDifference = 10;
        let previous_poses = [[0, 0],[0, 0],[0, 0],[0, 0],[0, 0],[0, 0],[0, 0],[0, 0],[0, 0],[0, 0],[0, 0],[0, 0],[0, 0],[0, 0],[0, 0],[0, 0],[0, 0]]
        let normalized_arr = [[],[],[],[],[],[],[],[],[],[],[],[],[],[],[],[], []];
        let initalized = false;


        async function init() {
            async function render() {
                try {
                   
                    if (video.currentTime >= video.duration) {
                        console.log(normalized_arr);
                        return;
                    }
                    
                    const startTime = new Date().getTime()
                    let normalized = []
                    ctx.clearRect(0, 0, canvas.width, canvas.height);
                    ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
                    const tensor = tf.browser.fromPixels(canvas);
                    const poses = await detectorMain.estimatePoses(tensor);
                   

                    if (video.currentTime < 1 && !initalized) {
                        requestAnimationFrame(render);
                        return;
                    }
                    if (!initalized) {
                        video.currentTime = 0;
                    }
                    initalized = true;
                    
                    origin = poses[0].keypoints[5];
                    destination = poses[0].keypoints[12];

                    let midpoint = [(origin.x + destination.x)/2, (origin.y + destination.y)/2];
                    let movementDifference = Math.abs(origin.y - destination.y) / 6;

                    previousMovementDifference = movementDifference;

                    for(let idx=0; idx<poses[0].keypoints.length; idx++) {
                        if (idx < 6 || idx === 11 || idx === 12) {
                            normalized_arr[idx].push([0, 0]);
                            continue;
                        }
                        let curr_pose = poses[0].keypoints[idx];
                        normalized_arr[idx].push([curr_pose.x - midpoint[0], midpoint[1] - curr_pose.y])
                    }

                    ctx.beginPath();
                    ctx.arc(midpoint[0], midpoint[1], 20, 0, 2 * Math.PI);
                    ctx.fillStyle = 'green';
                    ctx.fill();

                    poses[0].keypoints.forEach((keypoint, idx) => {
                        if (!(idx === 5 || idx === 6 || idx === 11 || idx === 12)) {
                            return
                        }
                        ctx.beginPath();
                        ctx.arc(keypoint.x, keypoint.y, 10, 0, 2 * Math.PI);
                        ctx.fillStyle = 'red';
                        ctx.fill();
                    });

            
                    tensor.dispose();
                    const endTime = new Date().getTime();
                    const executionTimeMs = endTime - startTime;


                    video.currentTime += 0.1;
                    requestAnimationFrame(render);
                } catch(e) {
                    console.log(e);
                    tensor.dispose();
                }
            }

            const model = poseDetection.SupportedModels.MoveNet;
            poseDetection.createDetector(model)
            .then(detector => {
                console.log(detector);
                detectorMain = detector;
                video.play();
                render();
            })
            .catch(error => {
                console.error('Error creating pose detector:', error);
            });
        }


        video.addEventListener('loadeddata', () => {
            videoWidth = video.videoWidth;
           videoHeight = video.videoHeight;
            canvas.width = videoWidth;
            canvas.height = videoHeight;
            init();
            
        });

    
    </script>
</body>
</html>